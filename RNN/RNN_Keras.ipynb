{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('SP500_train.csv')\n",
    "test = pd.read_csv('SP500_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>1258.859985</td>\n",
       "      <td>1284.619995</td>\n",
       "      <td>1258.859985</td>\n",
       "      <td>1277.060059</td>\n",
       "      <td>1277.060059</td>\n",
       "      <td>3943710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>1277.030029</td>\n",
       "      <td>1278.729980</td>\n",
       "      <td>1268.099976</td>\n",
       "      <td>1277.300049</td>\n",
       "      <td>1277.300049</td>\n",
       "      <td>3592580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1277.300049</td>\n",
       "      <td>1283.050049</td>\n",
       "      <td>1265.260010</td>\n",
       "      <td>1281.060059</td>\n",
       "      <td>1281.060059</td>\n",
       "      <td>4315950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>1280.930054</td>\n",
       "      <td>1281.839966</td>\n",
       "      <td>1273.339966</td>\n",
       "      <td>1277.810059</td>\n",
       "      <td>1277.810059</td>\n",
       "      <td>3656830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>1277.829956</td>\n",
       "      <td>1281.989990</td>\n",
       "      <td>1274.550049</td>\n",
       "      <td>1280.699951</td>\n",
       "      <td>1280.699951</td>\n",
       "      <td>3371600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         open         high          low        close  \\\n",
       "0  2012-01-03  1258.859985  1284.619995  1258.859985  1277.060059   \n",
       "1  2012-01-04  1277.030029  1278.729980  1268.099976  1277.300049   \n",
       "2  2012-01-05  1277.300049  1283.050049  1265.260010  1281.060059   \n",
       "3  2012-01-06  1280.930054  1281.839966  1273.339966  1277.810059   \n",
       "4  2012-01-09  1277.829956  1281.989990  1274.550049  1280.699951   \n",
       "\n",
       "     adj_close      volume  \n",
       "0  1277.060059  3943710000  \n",
       "1  1277.300049  3592580000  \n",
       "2  1281.060059  4315950000  \n",
       "3  1277.810059  3656830000  \n",
       "4  1280.699951  3371600000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.iloc[:, 5:6].values\n",
    "test_df = test.iloc[:, 5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler()\n",
    "scaled_train = minmax.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(40, n):\n",
    "    x_train.append(scaled_train[i - 40 : i, 0])\n",
    "    y_train.append(scaled_train[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00024128, 0.00402148, 0.00075403, 0.00365943,\n",
       "       0.01510054, 0.01550271, 0.01853894, 0.01209449, 0.01669916,\n",
       "       0.0311463 , 0.03764095, 0.03852568, 0.039149  , 0.03779178,\n",
       "       0.04926307, 0.0415921 , 0.03948073, 0.03614296, 0.03553976,\n",
       "       0.0472824 , 0.04874026, 0.06820418, 0.06763105, 0.07036575,\n",
       "       0.07329128, 0.07529196, 0.06593204, 0.07511106, 0.07383422,\n",
       "       0.06652517, 0.08141474, 0.08462181, 0.08560705, 0.0810327 ,\n",
       "       0.08686376, 0.08915603, 0.09101594, 0.09563067, 0.08909577])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09755083705434409"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1218, 40)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1218, 40, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\n",
    "model.add(Dropout (0.5))\n",
    "model.add(LSTM(units = 25, return_sequences = True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units = 25))\n",
    "model.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 40, 50)            10400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 40, 25)            7600      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 23,126\n",
      "Trainable params: 23,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1218/1218 [==============================] - 16s 13ms/step - loss: 0.0673\n",
      "Epoch 2/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0061\n",
      "Epoch 3/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0043\n",
      "Epoch 4/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0038\n",
      "Epoch 5/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0036\n",
      "Epoch 6/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0031\n",
      "Epoch 7/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0031\n",
      "Epoch 8/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0029\n",
      "Epoch 9/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0028\n",
      "Epoch 10/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0027\n",
      "Epoch 11/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0029\n",
      "Epoch 12/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0026\n",
      "Epoch 13/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0027\n",
      "Epoch 14/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0025\n",
      "Epoch 15/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0024\n",
      "Epoch 16/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0025\n",
      "Epoch 17/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0025\n",
      "Epoch 18/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0026\n",
      "Epoch 19/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0025\n",
      "Epoch 20/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0023\n",
      "Epoch 21/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0020\n",
      "Epoch 22/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0020\n",
      "Epoch 23/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0021\n",
      "Epoch 24/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0022\n",
      "Epoch 25/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0022\n",
      "Epoch 26/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0024\n",
      "Epoch 27/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0020\n",
      "Epoch 28/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0019\n",
      "Epoch 29/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0021\n",
      "Epoch 30/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0018\n",
      "Epoch 31/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0017\n",
      "Epoch 32/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0017\n",
      "Epoch 33/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0018\n",
      "Epoch 34/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0022\n",
      "Epoch 35/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0018\n",
      "Epoch 36/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0018\n",
      "Epoch 37/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0018\n",
      "Epoch 38/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0018\n",
      "Epoch 39/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0017\n",
      "Epoch 40/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0017\n",
      "Epoch 41/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0016\n",
      "Epoch 42/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0016\n",
      "Epoch 43/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0016\n",
      "Epoch 44/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0016\n",
      "Epoch 45/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0015\n",
      "Epoch 46/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0015\n",
      "Epoch 47/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0015\n",
      "Epoch 48/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0015\n",
      "Epoch 49/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0015\n",
      "Epoch 50/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0014\n",
      "Epoch 51/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0016\n",
      "Epoch 52/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0015\n",
      "Epoch 53/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0016\n",
      "Epoch 54/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0014\n",
      "Epoch 55/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0015\n",
      "Epoch 56/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0016\n",
      "Epoch 57/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0014\n",
      "Epoch 58/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 59/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 60/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0014\n",
      "Epoch 61/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0025\n",
      "Epoch 62/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0014\n",
      "Epoch 63/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 64/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 65/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0015\n",
      "Epoch 66/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0014\n",
      "Epoch 67/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 68/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 69/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 70/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0012\n",
      "Epoch 71/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0013\n",
      "Epoch 72/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0014\n",
      "Epoch 73/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0013\n",
      "Epoch 74/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0012\n",
      "Epoch 75/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0015\n",
      "Epoch 76/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0012\n",
      "Epoch 77/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0013\n",
      "Epoch 78/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 79/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 80/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0013\n",
      "Epoch 81/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0014\n",
      "Epoch 82/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0012\n",
      "Epoch 83/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0016\n",
      "Epoch 84/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0012\n",
      "Epoch 85/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0012\n",
      "Epoch 86/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0011\n",
      "Epoch 87/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0014\n",
      "Epoch 88/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0011\n",
      "Epoch 89/100\n",
      "1218/1218 [==============================] - 3s 3ms/step - loss: 0.0012\n",
      "Epoch 90/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 91/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 92/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0012\n",
      "Epoch 93/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0012\n",
      "Epoch 94/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 95/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0012\n",
      "Epoch 96/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0011\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0013\n",
      "Epoch 98/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0012\n",
      "Epoch 99/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0012\n",
      "Epoch 100/100\n",
      "1218/1218 [==============================] - 3s 2ms/step - loss: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1642f408c48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss = 'mean_squared_error')\n",
    "model.fit(x_train, y_train,epochs = 100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.06726443535710987,\n",
       "  0.006129732516048284,\n",
       "  0.004275339903319117,\n",
       "  0.003783543014972301,\n",
       "  0.003554797549930834,\n",
       "  0.0031121893845535266,\n",
       "  0.0031152211549448704,\n",
       "  0.0029347839601619294,\n",
       "  0.002843383617839839,\n",
       "  0.0027283084309661426,\n",
       "  0.0029480821240467,\n",
       "  0.0025814452926568652,\n",
       "  0.002678488744980975,\n",
       "  0.0024623760283727365,\n",
       "  0.002418512579402313,\n",
       "  0.0024537940177766756,\n",
       "  0.0024823457467536424,\n",
       "  0.0026423903247142708,\n",
       "  0.002463747251569332,\n",
       "  0.0022719599847943325,\n",
       "  0.0019633774022450932,\n",
       "  0.001981536899073958,\n",
       "  0.002061031390614624,\n",
       "  0.0021708652132254994,\n",
       "  0.0021714391715385705,\n",
       "  0.0023533135082126153,\n",
       "  0.001991185011175478,\n",
       "  0.001894802765764773,\n",
       "  0.0020733303975387306,\n",
       "  0.0017758058869602597,\n",
       "  0.0016777355838754353,\n",
       "  0.0016957752212380442,\n",
       "  0.0018490556679506998,\n",
       "  0.0022237136323855233,\n",
       "  0.0017922609375999271,\n",
       "  0.0018268376581175084,\n",
       "  0.0018221075194585787,\n",
       "  0.001813761090128782,\n",
       "  0.0017407850687042618,\n",
       "  0.0017423916928571831,\n",
       "  0.0015884688562195143,\n",
       "  0.0016370016226257475,\n",
       "  0.0015549409936896367,\n",
       "  0.0016176294139844452,\n",
       "  0.0014913054349672047,\n",
       "  0.0014729963276039792,\n",
       "  0.0014944447694122272,\n",
       "  0.0014716820379991346,\n",
       "  0.0015473086773058512,\n",
       "  0.0014393579041622028,\n",
       "  0.0015653605430084167,\n",
       "  0.001484415184611635,\n",
       "  0.0015510682760980989,\n",
       "  0.0013956967741788624,\n",
       "  0.0015416095182009054,\n",
       "  0.001590400082669477,\n",
       "  0.0014010120801817266,\n",
       "  0.001308849810761031,\n",
       "  0.0013106550676010287,\n",
       "  0.0014049612132492912,\n",
       "  0.002454227405030694,\n",
       "  0.001423257910878397,\n",
       "  0.001275763378500761,\n",
       "  0.0013168743596112505,\n",
       "  0.0014726855554686759,\n",
       "  0.0013651272601429647,\n",
       "  0.0013279936047751084,\n",
       "  0.0012861346421275464,\n",
       "  0.0013165323087434807,\n",
       "  0.0012333258752877808,\n",
       "  0.0012750140531217963,\n",
       "  0.0013975044672758959,\n",
       "  0.0012694847940548349,\n",
       "  0.0012467673588590009,\n",
       "  0.0015468217039860063,\n",
       "  0.0011932796673246695,\n",
       "  0.0013377745794946685,\n",
       "  0.0012549320506815124,\n",
       "  0.001277844915135912,\n",
       "  0.0012556854068573636,\n",
       "  0.0013513027907124367,\n",
       "  0.00119037814484221,\n",
       "  0.0016315038300324645,\n",
       "  0.001223791960977807,\n",
       "  0.001203277102828648,\n",
       "  0.0011104456254560958,\n",
       "  0.0013559053988474665,\n",
       "  0.0010881195667204377,\n",
       "  0.0011865112105497635,\n",
       "  0.0012676782068018059,\n",
       "  0.001282546056774009,\n",
       "  0.001168957547084329,\n",
       "  0.0011989717725022085,\n",
       "  0.0012739632138753026,\n",
       "  0.0011801221244509695,\n",
       "  0.0011191620905875964,\n",
       "  0.0012584493152586183,\n",
       "  0.0011603130033004216,\n",
       "  0.0011922698146824178,\n",
       "  0.001133903333449305]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x164395171c8>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = [i for i in range(100)]\n",
    "plt.plot(x_axis, model.history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>2260.250000</td>\n",
       "      <td>2263.790039</td>\n",
       "      <td>2258.840088</td>\n",
       "      <td>2263.790039</td>\n",
       "      <td>2263.790039</td>\n",
       "      <td>2020550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>2266.229980</td>\n",
       "      <td>2273.820068</td>\n",
       "      <td>2266.149902</td>\n",
       "      <td>2268.879883</td>\n",
       "      <td>2268.879883</td>\n",
       "      <td>1987080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>2270.229980</td>\n",
       "      <td>2271.310059</td>\n",
       "      <td>2249.110107</td>\n",
       "      <td>2249.919922</td>\n",
       "      <td>2249.919922</td>\n",
       "      <td>2392360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>2249.500000</td>\n",
       "      <td>2254.510010</td>\n",
       "      <td>2244.560059</td>\n",
       "      <td>2249.260010</td>\n",
       "      <td>2249.260010</td>\n",
       "      <td>2336370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>2251.610107</td>\n",
       "      <td>2253.580078</td>\n",
       "      <td>2233.620117</td>\n",
       "      <td>2238.830078</td>\n",
       "      <td>2238.830078</td>\n",
       "      <td>2670900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date         open         high          low        close  \\\n",
       "1253  2016-12-23  2260.250000  2263.790039  2258.840088  2263.790039   \n",
       "1254  2016-12-27  2266.229980  2273.820068  2266.149902  2268.879883   \n",
       "1255  2016-12-28  2270.229980  2271.310059  2249.110107  2249.919922   \n",
       "1256  2016-12-29  2249.500000  2254.510010  2244.560059  2249.260010   \n",
       "1257  2016-12-30  2251.610107  2253.580078  2233.620117  2238.830078   \n",
       "\n",
       "        adj_close      volume  \n",
       "1253  2263.790039  2020550000  \n",
       "1254  2268.879883  1987080000  \n",
       "1255  2249.919922  2392360000  \n",
       "1256  2249.260010  2336370000  \n",
       "1257  2238.830078  2670900000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 40, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[-1:-40:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9813145]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[-1].reshape((1,40,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
